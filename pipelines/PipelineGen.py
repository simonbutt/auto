import openai
import json
import pipelines.prompts as prompt
import logging


class PipelineGen:
    
    """
        PipelineGen is a class that contains the methods to generate Vertex pipeline components based on the user's input.
        
        PipelineGen uses the OpenAI GPT-3 API to generate the code. 
        It will then attempt to deploy the code to the user's Google Cloud environment and learn from failed pipeline runs.
    """
    
    def __init__(self, system_prefix: str, template_prompt: str, model_name: str, max_token_length: int=4097) -> None:
        self.system_context = f"{system_prefix}\n{template_prompt}"
        self.model_name = model_name
        self.max_token_length = max_token_length
        
    def _get_code(self, choice_config: dict) -> str:
        response_code_list = choice_config["message"]["content"].split("```")
        if len(response_code_list) > 1:
            return response_code_list[1].removeprefix("\n")
        else:
            logging.warning("Generated response snippet doesn't contain ``` code block, highly likely to be incorrect")
            return response_code_list[0]
        
    def _generate_component_code_snippets(self, component_message_chain: list, n_shot: int) -> str:
        
        # max_tokens stops the review_n_components method from max_tokening out
        max_component_tokens=(self.max_token_length - int((len(prompt.PIPELINE_TEMPLATE_PROMPT + prompt.COMPONNT_SYSTEM_PROMPT)) / 3))
        logging.debug(f"Max component tokens: {max_component_tokens}")
        response = openai.ChatCompletion.create(
            model=self.model_name,
            messages=component_message_chain,
            n=n_shot,
            max_tokens=max_component_tokens // n_shot,
        )
        return [self._get_code(response["choices"][i]) for i in range(len(response["choices"]))]
    
    def _review_n_components(self, nshot_messages: list) -> str:
        """
        Takes n component code snippets and returns the snippet with the highest accuracy score.
        This score is determined by the model and is based on prompt.REVIEW_NSHOT_PROMPT.
        """
        snippet_txt = "\n\n".join([
            f"{i}.\n```{nshot_messages[i]}```" for i in range(len(nshot_messages))
        ])
        
        logging.debug(f"Component snippet text: {snippet_txt}")
        
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": prompt.REVIEW_NSHOT_PROMPT},
                {"role": "user", "content": f"{snippet_txt}\n{prompt.REVIEW_RETURN_STRUCT}"}
            ],
            temperature=0.2
        )
        review_config_raw = response["choices"][0]["message"]["content"]

        try:
            review_config = json.loads(review_config_raw)
            # Returns the a config with in format {accuracy_score: snippet_name}
            accuracy_key_config = res = {
                val["accuracy_score"]: [val["snippet_name"], val["accuracy_summary"]] for val in review_config
            }
            # Chooses the snippet with the highest accuracy score
            key = max(accuracy_key_config.keys())
            return nshot_messages[accuracy_key_config[key][0]], f"Accuracy Prediction: {key}%\nAccuracy Summary: {accuracy_key_config[key][1]}"
            
        except json.JSONDecodeError:
            logging.warning(f"Review config JSON decode error: {review_config_raw}, returning initial n_shot message.")
            return nshot_messages[0], f"Failed to review {len(nshot_messages)} n_shot component snippets."
        
         
    
    def generate_example_pipeline(self) -> str:
        """
            TODO
            Generates a pipeline that includes the component code generated by generate_component
        """
        self.component_message_chain.append({"role": "system", "content": prompt.PIPELINE_TEMPLATE_PROMPT})
        self._generate()
    

    def generate_component(self, input_content, n_shot=3):
        """
            Completes an iteration of:
            - Given latest input, model generates code
            - Model code is written to file as a pipeline component
            - Component is compiled
            - Example pipeline run including only the component code is created
            - Human evaluates the pipeline run code and approves
            - pipeline is deployed and successfully runs on Vertex AI
            - Test output data against expected output.
            
            If the pipeline run fails, the self.message_chain is updated and the process is repeated.
        """
        if input_content == "":
            return "No input description... \n Recommend trying one of the examples!", ""
        
        component_message_chain=[
            {"role": "system", "content": self.system_context}
        ]
        component_message_chain.append({"role": "user", "content": input_content})
        
        # Generate component code and output to .py file
        n_shot_response_list = self._generate_component_code_snippets(component_message_chain, n_shot)
        
        component_code, accuracy_txt = self._review_n_components(n_shot_response_list)
        
        component_message_chain.append({"role": "assistant", "content": component_code})
        return component_code, accuracy_txt
        

if __name__ == "__main__":

    import os
    
    log_dict = {
        "debug": logging.DEBUG,
        "info": logging.INFO,
        "warning": logging.WARNING,
        "error": logging.ERROR
    }
    
    # Log Level default to INFO
    logging.basicConfig(level=log_dict.get(os.getenv("LOG_LEVEL", "INFO").lower(), "INFO"))
    model_name: str = os.getenv("MODEL_NAME")

    
    pgen = PipelineGen(
        system_prefix=prompt.SYSTEM_PREFIX,
        template_prompt=prompt.COMPONENT_TEMPLATE_PROMPT,
        model_name=model_name
    )
    
    pgen.generate_component(
        input_content="Write a component that takes a GCS path containing multiple images (either .png or .json) {image_path: string} from a GCS bucket and uses grabcut to segment the images into a foreground and background. The component should output the foreground and background images to the GCS bucket in folder path {output_gcs_folder: string}.",
        n_shot=3
    )
    